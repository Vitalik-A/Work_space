{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7, -1],\n",
       "       [-4,  2,  5],\n",
       "       [ 0,  9,  7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array( [[ 4 , 7 ,-1],[ -4 , 2 , 5],[ 0 ,9,  7]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, -1,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.6.1\n",
    "b=np.array([1,2,2])\n",
    "A=np.array([[1,-5],[2,1],[1,1]])\n",
    "w_=np.array([1,1])\n",
    "e=b-A@w_\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.6.3\n",
    "A=np.array([[1,2],[-3,1],[1,2],[1,-1]])\n",
    "b=np.array([1,4,5,0])\n",
    "A.T@A # матрица Грама"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08333333, 0.        ],\n",
       "       [0.        , 0.1       ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A.T@A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  1.6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A.T@A)@(A.T@b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 0, 4],\n",
       "       [4, 6, 0, 6],\n",
       "       [0, 0, 2, 2],\n",
       "       [4, 6, 2, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=np.array([[1,1,-1,0],[1,1,1,2],[1,0,0,0],[1,2,0,2]])\n",
    "m.T@m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "#2.11\n",
    "df=pd.read_csv('Admission_Predict.csv')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Serial No.'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-46c77e47761e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Serial No.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Serial No.'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(['Serial No.'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827200</td>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.563398</td>\n",
       "      <td>0.810351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.827200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.541563</td>\n",
       "      <td>0.810574</td>\n",
       "      <td>0.467012</td>\n",
       "      <td>0.792228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728024</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.427047</td>\n",
       "      <td>0.690132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.728024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663707</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.408116</td>\n",
       "      <td>0.684137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.541563</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.663707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637469</td>\n",
       "      <td>0.372526</td>\n",
       "      <td>0.645365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.810574</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.637469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>0.882413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.563398</td>\n",
       "      <td>0.467012</td>\n",
       "      <td>0.427047</td>\n",
       "      <td>0.408116</td>\n",
       "      <td>0.372526</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.810351</td>\n",
       "      <td>0.792228</td>\n",
       "      <td>0.690132</td>\n",
       "      <td>0.684137</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.882413</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.827200           0.635376  0.613498   \n",
       "TOEFL Score         0.827200     1.000000           0.649799  0.644410   \n",
       "University Rating   0.635376     0.649799           1.000000  0.728024   \n",
       "SOP                 0.613498     0.644410           0.728024  1.000000   \n",
       "LOR                 0.524679     0.541563           0.608651  0.663707   \n",
       "CGPA                0.825878     0.810574           0.705254  0.712154   \n",
       "Research            0.563398     0.467012           0.427047  0.408116   \n",
       "Chance of Admit     0.810351     0.792228           0.690132  0.684137   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.524679  0.825878  0.563398          0.810351  \n",
       "TOEFL Score        0.541563  0.810574  0.467012          0.792228  \n",
       "University Rating  0.608651  0.705254  0.427047          0.690132  \n",
       "SOP                0.663707  0.712154  0.408116          0.684137  \n",
       "LOR                1.000000  0.637469  0.372526          0.645365  \n",
       "CGPA               0.637469  1.000000  0.501311          0.882413  \n",
       "Research           0.372526  0.501311  1.000000          0.545871  \n",
       "Chance of Admit    0.645365  0.882413  0.545871          1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=df.corr(method='pearson')\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr0=df[df.Research==0]\n",
    "dr1=df[df.Research==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680668</td>\n",
       "      <td>0.384715</td>\n",
       "      <td>0.371424</td>\n",
       "      <td>0.365864</td>\n",
       "      <td>0.678476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.680668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495748</td>\n",
       "      <td>0.476563</td>\n",
       "      <td>0.470956</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.384715</td>\n",
       "      <td>0.495748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>0.484262</td>\n",
       "      <td>0.516427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.428580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.371424</td>\n",
       "      <td>0.476563</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618680</td>\n",
       "      <td>0.547098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.365864</td>\n",
       "      <td>0.470956</td>\n",
       "      <td>0.484262</td>\n",
       "      <td>0.618680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.678476</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.516427</td>\n",
       "      <td>0.547098</td>\n",
       "      <td>0.562517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.603827</td>\n",
       "      <td>0.622458</td>\n",
       "      <td>0.428580</td>\n",
       "      <td>0.470188</td>\n",
       "      <td>0.542528</td>\n",
       "      <td>0.752714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.680668           0.384715  0.371424   \n",
       "TOEFL Score         0.680668     1.000000           0.495748  0.476563   \n",
       "University Rating   0.384715     0.495748           1.000000  0.607496   \n",
       "SOP                 0.371424     0.476563           0.607496  1.000000   \n",
       "LOR                 0.365864     0.470956           0.484262  0.618680   \n",
       "CGPA                0.678476     0.696774           0.516427  0.547098   \n",
       "Research                 NaN          NaN                NaN       NaN   \n",
       "Chance of Admit     0.603827     0.622458           0.428580  0.470188   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.365864  0.678476       NaN          0.603827  \n",
       "TOEFL Score        0.470956  0.696774       NaN          0.622458  \n",
       "University Rating  0.484262  0.516427       NaN          0.428580  \n",
       "SOP                0.618680  0.547098       NaN          0.470188  \n",
       "LOR                1.000000  0.562517       NaN          0.542528  \n",
       "CGPA               0.562517  1.000000       NaN          0.752714  \n",
       "Research                NaN       NaN       NaN               NaN  \n",
       "Chance of Admit    0.542528  0.752714       NaN          1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr0C=dr0.corr(method='pearson')\n",
    "dr0C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824170</td>\n",
       "      <td>0.614739</td>\n",
       "      <td>0.613318</td>\n",
       "      <td>0.443374</td>\n",
       "      <td>0.806720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.824170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602445</td>\n",
       "      <td>0.629436</td>\n",
       "      <td>0.436199</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.614739</td>\n",
       "      <td>0.602445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723126</td>\n",
       "      <td>0.573881</td>\n",
       "      <td>0.692237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.713094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.613318</td>\n",
       "      <td>0.629436</td>\n",
       "      <td>0.723126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591858</td>\n",
       "      <td>0.717750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.443374</td>\n",
       "      <td>0.436199</td>\n",
       "      <td>0.573881</td>\n",
       "      <td>0.591858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.806720</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.692237</td>\n",
       "      <td>0.717750</td>\n",
       "      <td>0.564794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.802439</td>\n",
       "      <td>0.787180</td>\n",
       "      <td>0.713094</td>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.588558</td>\n",
       "      <td>0.892489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.824170           0.614739  0.613318   \n",
       "TOEFL Score         0.824170     1.000000           0.602445  0.629436   \n",
       "University Rating   0.614739     0.602445           1.000000  0.723126   \n",
       "SOP                 0.613318     0.629436           0.723126  1.000000   \n",
       "LOR                 0.443374     0.436199           0.573881  0.591858   \n",
       "CGPA                0.806720     0.784173           0.692237  0.717750   \n",
       "Research                 NaN          NaN                NaN       NaN   \n",
       "Chance of Admit     0.802439     0.787180           0.713094  0.708238   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.443374  0.806720       NaN          0.802439  \n",
       "TOEFL Score        0.436199  0.784173       NaN          0.787180  \n",
       "University Rating  0.573881  0.692237       NaN          0.713094  \n",
       "SOP                0.591858  0.717750       NaN          0.708238  \n",
       "LOR                1.000000  0.564794       NaN          0.588558  \n",
       "CGPA               0.564794  1.000000       NaN          0.892489  \n",
       "Research                NaN       NaN       NaN               NaN  \n",
       "Chance of Admit    0.588558  0.892489       NaN          1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr1C=dr1.corr(method='pearson')\n",
    "dr1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 220 entries, 4 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          220 non-null    int64  \n",
      " 1   TOEFL Score        220 non-null    int64  \n",
      " 2   University Rating  220 non-null    int64  \n",
      " 3   SOP                220 non-null    float64\n",
      " 4   LOR                220 non-null    float64\n",
      " 5   CGPA               220 non-null    float64\n",
      " 6   Research           220 non-null    int64  \n",
      " 7   Chance of Admit    220 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 15.5 KB\n"
     ]
    }
   ],
   "source": [
    "dr0.info()\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 103.  ,   8.21],\n",
       "       [  1.  , 101.  ,   7.9 ],\n",
       "       [  1.  , 102.  ,   8.  ],\n",
       "       [  1.  , 108.  ,   8.6 ],\n",
       "       [  1.  , 105.  ,   8.3 ],\n",
       "       [  1.  , 107.  ,   8.7 ],\n",
       "       [  1.  , 110.  ,   8.8 ],\n",
       "       [  1.  , 102.  ,   8.5 ],\n",
       "       [  1.  , 114.  ,   8.4 ],\n",
       "       [  1.  , 109.  ,   8.8 ],\n",
       "       [  1.  ,  93.  ,   7.2 ],\n",
       "       [  1.  ,  99.  ,   7.3 ],\n",
       "       [  1.  , 106.  ,   8.4 ],\n",
       "       [  1.  , 105.  ,   7.8 ],\n",
       "       [  1.  , 105.  ,   7.5 ],\n",
       "       [  1.  , 108.  ,   7.7 ],\n",
       "       [  1.  , 117.  ,   9.1 ],\n",
       "       [  1.  , 119.  ,   9.7 ],\n",
       "       [  1.  , 110.  ,   8.  ],\n",
       "       [  1.  , 103.  ,   7.7 ],\n",
       "       [  1.  , 102.  ,   7.4 ],\n",
       "       [  1.  ,  99.  ,   7.6 ],\n",
       "       [  1.  , 104.  ,   8.3 ],\n",
       "       [  1.  , 100.  ,   8.1 ],\n",
       "       [  1.  , 101.  ,   8.2 ],\n",
       "       [  1.  , 111.  ,   8.7 ],\n",
       "       [  1.  , 112.  ,   8.92],\n",
       "       [  1.  , 114.  ,   9.02],\n",
       "       [  1.  , 106.  ,   8.9 ],\n",
       "       [  1.  ,  99.  ,   8.22],\n",
       "       [  1.  ,  93.  ,   7.36],\n",
       "       [  1.  , 103.  ,   8.66],\n",
       "       [  1.  , 106.  ,   8.42],\n",
       "       [  1.  , 107.  ,   8.28],\n",
       "       [  1.  , 108.  ,   8.14],\n",
       "       [  1.  ,  97.  ,   7.66],\n",
       "       [  1.  ,  98.  ,   8.03],\n",
       "       [  1.  ,  99.  ,   7.66],\n",
       "       [  1.  , 100.  ,   7.84],\n",
       "       [  1.  , 100.  ,   8.  ],\n",
       "       [  1.  , 105.  ,   8.12],\n",
       "       [  1.  , 106.  ,   8.25],\n",
       "       [  1.  , 104.  ,   8.47],\n",
       "       [  1.  , 103.  ,   8.64],\n",
       "       [  1.  , 108.  ,   8.48],\n",
       "       [  1.  , 110.  ,   8.56],\n",
       "       [  1.  , 102.  ,   8.62],\n",
       "       [  1.  , 104.  ,   7.46],\n",
       "       [  1.  ,  99.  ,   7.28],\n",
       "       [  1.  , 106.  ,   8.36],\n",
       "       [  1.  , 108.  ,   8.22],\n",
       "       [  1.  , 106.  ,   8.47],\n",
       "       [  1.  , 105.  ,   8.65],\n",
       "       [  1.  , 105.  ,   8.56],\n",
       "       [  1.  , 112.  ,   8.78],\n",
       "       [  1.  , 103.  ,   8.45],\n",
       "       [  1.  , 109.  ,   9.12],\n",
       "       [  1.  , 105.  ,   8.48],\n",
       "       [  1.  , 105.  ,   8.75],\n",
       "       [  1.  , 108.  ,   8.89],\n",
       "       [  1.  , 109.  ,   8.69],\n",
       "       [  1.  , 105.  ,   8.34],\n",
       "       [  1.  , 104.  ,   8.26],\n",
       "       [  1.  , 106.  ,   8.14],\n",
       "       [  1.  , 100.  ,   7.9 ],\n",
       "       [  1.  , 103.  ,   7.86],\n",
       "       [  1.  ,  99.  ,   7.46],\n",
       "       [  1.  , 109.  ,   8.5 ],\n",
       "       [  1.  , 105.  ,   8.56],\n",
       "       [  1.  , 110.  ,   8.97],\n",
       "       [  1.  , 102.  ,   8.33],\n",
       "       [  1.  , 102.  ,   8.27],\n",
       "       [  1.  ,  99.  ,   7.98],\n",
       "       [  1.  , 110.  ,   9.04],\n",
       "       [  1.  , 108.  ,   8.12],\n",
       "       [  1.  , 102.  ,   8.27],\n",
       "       [  1.  , 104.  ,   8.16],\n",
       "       [  1.  , 107.  ,   8.42],\n",
       "       [  1.  , 100.  ,   7.88],\n",
       "       [  1.  , 110.  ,   8.8 ],\n",
       "       [  1.  , 106.  ,   8.32],\n",
       "       [  1.  , 109.  ,   8.76],\n",
       "       [  1.  , 105.  ,   8.26],\n",
       "       [  1.  , 106.  ,   8.33],\n",
       "       [  1.  , 104.  ,   8.43],\n",
       "       [  1.  , 107.  ,   8.69],\n",
       "       [  1.  , 105.  ,   8.54],\n",
       "       [  1.  ,  99.  ,   7.65],\n",
       "       [  1.  ,  99.  ,   7.89],\n",
       "       [  1.  , 106.  ,   8.16],\n",
       "       [  1.  , 104.  ,   8.42],\n",
       "       [  1.  , 103.  ,   8.75],\n",
       "       [  1.  , 110.  ,   8.56],\n",
       "       [  1.  , 113.  ,   8.79],\n",
       "       [  1.  , 109.  ,   8.45],\n",
       "       [  1.  , 105.  ,   8.23],\n",
       "       [  1.  ,  99.  ,   8.03],\n",
       "       [  1.  , 110.  ,   8.45],\n",
       "       [  1.  , 110.  ,   8.53],\n",
       "       [  1.  , 112.  ,   8.67],\n",
       "       [  1.  , 104.  ,   8.65],\n",
       "       [  1.  , 107.  ,   8.27],\n",
       "       [  1.  , 100.  ,   8.07],\n",
       "       [  1.  , 104.  ,   8.37],\n",
       "       [  1.  , 100.  ,   7.89],\n",
       "       [  1.  , 101.  ,   7.68],\n",
       "       [  1.  , 103.  ,   8.15],\n",
       "       [  1.  , 107.  ,   8.56],\n",
       "       [  1.  , 105.  ,   8.73],\n",
       "       [  1.  , 104.  ,   8.48],\n",
       "       [  1.  ,  99.  ,   9.  ],\n",
       "       [  1.  , 114.  ,   9.12],\n",
       "       [  1.  , 110.  ,   8.37],\n",
       "       [  1.  ,  99.  ,   8.56],\n",
       "       [  1.  , 104.  ,   8.09],\n",
       "       [  1.  , 102.  ,   8.68],\n",
       "       [  1.  , 105.  ,   8.45],\n",
       "       [  1.  , 113.  ,   9.14],\n",
       "       [  1.  , 108.  ,   8.34],\n",
       "       [  1.  ,  96.  ,   7.86],\n",
       "       [  1.  ,  95.  ,   7.64],\n",
       "       [  1.  , 100.  ,   7.95],\n",
       "       [  1.  , 101.  ,   8.62],\n",
       "       [  1.  , 103.  ,   8.49],\n",
       "       [  1.  , 102.  ,   8.73],\n",
       "       [  1.  , 104.  ,   9.02],\n",
       "       [  1.  , 109.  ,   9.  ],\n",
       "       [  1.  , 105.  ,   7.65],\n",
       "       [  1.  , 102.  ,   7.87],\n",
       "       [  1.  ,  99.  ,   7.97],\n",
       "       [  1.  , 100.  ,   8.57],\n",
       "       [  1.  , 107.  ,   8.67],\n",
       "       [  1.  , 120.  ,   9.11],\n",
       "       [  1.  , 112.  ,   8.65],\n",
       "       [  1.  , 106.  ,   8.  ],\n",
       "       [  1.  , 108.  ,   8.76],\n",
       "       [  1.  , 106.  ,   8.43],\n",
       "       [  1.  , 108.  ,   8.53],\n",
       "       [  1.  , 110.  ,   8.6 ],\n",
       "       [  1.  , 100.  ,   8.04],\n",
       "       [  1.  , 105.  ,   8.13],\n",
       "       [  1.  , 104.  ,   8.07],\n",
       "       [  1.  , 101.  ,   7.86],\n",
       "       [  1.  ,  99.  ,   8.01],\n",
       "       [  1.  , 107.  ,   8.27],\n",
       "       [  1.  , 102.  ,   8.18],\n",
       "       [  1.  , 104.  ,   8.33],\n",
       "       [  1.  , 100.  ,   8.02],\n",
       "       [  1.  , 101.  ,   7.86],\n",
       "       [  1.  ,  96.  ,   7.89],\n",
       "       [  1.  , 110.  ,   8.79],\n",
       "       [  1.  , 106.  ,   8.24],\n",
       "       [  1.  , 103.  ,   8.13],\n",
       "       [  1.  ,  96.  ,   7.34],\n",
       "       [  1.  ,  98.  ,   7.43],\n",
       "       [  1.  ,  97.  ,   7.64],\n",
       "       [  1.  ,  94.  ,   7.34],\n",
       "       [  1.  ,  99.  ,   7.25],\n",
       "       [  1.  , 101.  ,   8.04],\n",
       "       [  1.  , 102.  ,   8.17],\n",
       "       [  1.  ,  98.  ,   7.67],\n",
       "       [  1.  , 106.  ,   8.12],\n",
       "       [  1.  , 105.  ,   7.64],\n",
       "       [  1.  , 107.  ,   8.44],\n",
       "       [  1.  , 103.  ,   8.36],\n",
       "       [  1.  ,  98.  ,   7.46],\n",
       "       [  1.  ,  92.  ,   7.88],\n",
       "       [  1.  , 103.  ,   8.24],\n",
       "       [  1.  , 105.  ,   7.65],\n",
       "       [  1.  , 101.  ,   7.66],\n",
       "       [  1.  ,  96.  ,   7.43],\n",
       "       [  1.  , 100.  ,   7.56],\n",
       "       [  1.  ,  98.  ,   7.65],\n",
       "       [  1.  , 100.  ,   8.26],\n",
       "       [  1.  , 101.  ,   7.96],\n",
       "       [  1.  , 105.  ,   8.1 ],\n",
       "       [  1.  ,  97.  ,   7.8 ],\n",
       "       [  1.  , 102.  ,   8.24],\n",
       "       [  1.  , 106.  ,   8.65],\n",
       "       [  1.  , 104.  ,   8.76],\n",
       "       [  1.  , 103.  ,   8.78],\n",
       "       [  1.  , 100.  ,   8.22],\n",
       "       [  1.  , 105.  ,   8.34],\n",
       "       [  1.  ,  99.  ,   7.45],\n",
       "       [  1.  ,  98.  ,   8.02],\n",
       "       [  1.  ,  96.  ,   7.56],\n",
       "       [  1.  ,  94.  ,   8.13],\n",
       "       [  1.  , 104.  ,   8.1 ],\n",
       "       [  1.  , 103.  ,   7.68],\n",
       "       [  1.  , 111.  ,   8.03],\n",
       "       [  1.  , 100.  ,   7.42],\n",
       "       [  1.  , 106.  ,   8.57],\n",
       "       [  1.  , 103.  ,   8.74],\n",
       "       [  1.  , 111.  ,   8.54],\n",
       "       [  1.  , 103.  ,   8.21],\n",
       "       [  1.  , 105.  ,   7.68],\n",
       "       [  1.  , 105.  ,   8.46],\n",
       "       [  1.  , 104.  ,   7.79],\n",
       "       [  1.  , 109.  ,   9.02],\n",
       "       [  1.  , 101.  ,   9.13],\n",
       "       [  1.  , 105.  ,   8.01],\n",
       "       [  1.  , 102.  ,   7.64],\n",
       "       [  1.  , 100.  ,   7.88],\n",
       "       [  1.  ,  99.  ,   7.57],\n",
       "       [  1.  , 105.  ,   7.94],\n",
       "       [  1.  , 107.  ,   7.86],\n",
       "       [  1.  ,  97.  ,   7.21],\n",
       "       [  1.  ,  96.  ,   8.26],\n",
       "       [  1.  , 103.  ,   8.09],\n",
       "       [  1.  , 102.  ,   8.15],\n",
       "       [  1.  , 101.  ,   7.88],\n",
       "       [  1.  , 104.  ,   8.12],\n",
       "       [  1.  , 105.  ,   8.18],\n",
       "       [  1.  , 103.  ,   7.92],\n",
       "       [  1.  , 102.  ,   8.37],\n",
       "       [  1.  , 115.  ,   9.14],\n",
       "       [  1.  , 110.  ,   8.5 ],\n",
       "       [  1.  ,  99.  ,   7.81],\n",
       "       [  1.  , 103.  ,   8.43],\n",
       "       [  1.  , 113.  ,   9.04]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Toef=dr0['TOEFL Score']\n",
    "CGPA=dr0['CGPA']\n",
    "tag=dr0[['Chance of Admit ']]\n",
    "A= np.column_stack((np.ones(220), Toef, CGPA))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.04486443],\n",
       "        [ 0.00442727],\n",
       "        [ 0.14807744]]),\n",
       " array([1.13772786]),\n",
       " 3,\n",
       " array([1548.98055048,    5.02503482,    0.67532963]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(A,tag,rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7297999999999998"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chance=-1.045+0.004*107+0.148*9.1\n",
    "chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value of Toef: 103.99090909090908\n",
      "mean value of CGPA: 8.234727272727275\n",
      "mean value of tag: Chance of Admit     0.634909\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# метод .mean() позволяет вычислить арифметическое среднее значение вектора\n",
    "meanToef = dr0['TOEFL Score'].mean()\n",
    "meanCGPA  = dr0['CGPA'].mean()\n",
    "mean_tag = tag.mean()\n",
    "print('mean value of Toef:',meanToef)\n",
    "print('mean value of CGPA:', meanCGPA)\n",
    "print('mean value of tag:',mean_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Центрирование\n",
    "Toef_c = dr0['TOEFL Score'] - meanToef\n",
    "CGPA_c = dr0['CGPA'] - meanCGPA\n",
    "tag_c = tag - mean_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляем длины векторов для нормирования\n",
    "Toef_c_norm = np.linalg.norm(Toef_c)\n",
    "CGPA_c_norm = np.linalg.norm(CGPA_c)\n",
    "tag_c_norm = np.linalg.norm(tag_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормирование: делим каждый центрированный вектор на его длину\n",
    "Toef_st=Toef_c / Toef_c_norm\n",
    "CGPA_st=CGPA_c / CGPA_c_norm\n",
    "tag_st=tag_c / tag_c_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01390829, -0.00356568],\n",
       "       [-0.04198007, -0.04826775],\n",
       "       [-0.02794418, -0.03384772],\n",
       "       [ 0.05627116,  0.05267241],\n",
       "       [ 0.01416349,  0.00941234],\n",
       "       [ 0.04223527,  0.06709243],\n",
       "       [ 0.08434294,  0.08151245],\n",
       "       [-0.02794418,  0.03825238],\n",
       "       [ 0.1404865 ,  0.02383236],\n",
       "       [ 0.07030705,  0.08151245],\n",
       "       [-0.1542672 , -0.1492079 ],\n",
       "       [-0.07005185, -0.13478788],\n",
       "       [ 0.02819938,  0.02383236],\n",
       "       [ 0.01416349, -0.06268777],\n",
       "       [ 0.01416349, -0.10594783],\n",
       "       [ 0.05627116, -0.07710779],\n",
       "       [ 0.18259418,  0.12477251],\n",
       "       [ 0.21066596,  0.21129264],\n",
       "       [ 0.08434294, -0.03384772],\n",
       "       [-0.01390829, -0.07710779],\n",
       "       [-0.02794418, -0.12036785],\n",
       "       [-0.07005185, -0.09152781],\n",
       "       [ 0.0001276 ,  0.00941234],\n",
       "       [-0.05601596, -0.0194277 ],\n",
       "       [-0.04198007, -0.00500768],\n",
       "       [ 0.09837883,  0.06709243],\n",
       "       [ 0.11241472,  0.09881648],\n",
       "       [ 0.1404865 ,  0.1132365 ],\n",
       "       [ 0.02819938,  0.09593247],\n",
       "       [-0.07005185, -0.00212368],\n",
       "       [-0.1542672 , -0.12613586],\n",
       "       [-0.01390829,  0.06132442],\n",
       "       [ 0.02819938,  0.02671637],\n",
       "       [ 0.04223527,  0.00652834],\n",
       "       [ 0.05627116, -0.01365969],\n",
       "       [-0.09812363, -0.0828758 ],\n",
       "       [-0.08408774, -0.02952172],\n",
       "       [-0.07005185, -0.0828758 ],\n",
       "       [-0.05601596, -0.05691976],\n",
       "       [-0.05601596, -0.03384772],\n",
       "       [ 0.01416349, -0.0165437 ],\n",
       "       [ 0.02819938,  0.00220233],\n",
       "       [ 0.0001276 ,  0.03392638],\n",
       "       [-0.01390829,  0.05844041],\n",
       "       [ 0.05627116,  0.03536838],\n",
       "       [ 0.08434294,  0.0469044 ],\n",
       "       [-0.02794418,  0.05555641],\n",
       "       [ 0.0001276 , -0.11171584],\n",
       "       [-0.07005185, -0.13767188],\n",
       "       [ 0.02819938,  0.01806435],\n",
       "       [ 0.05627116, -0.00212368],\n",
       "       [ 0.02819938,  0.03392638],\n",
       "       [ 0.01416349,  0.05988242],\n",
       "       [ 0.01416349,  0.0469044 ],\n",
       "       [ 0.11241472,  0.07862845],\n",
       "       [-0.01390829,  0.03104237],\n",
       "       [ 0.07030705,  0.12765652],\n",
       "       [ 0.01416349,  0.03536838],\n",
       "       [ 0.01416349,  0.07430244],\n",
       "       [ 0.05627116,  0.09449047],\n",
       "       [ 0.07030705,  0.06565043],\n",
       "       [ 0.01416349,  0.01518035],\n",
       "       [ 0.0001276 ,  0.00364433],\n",
       "       [ 0.02819938, -0.01365969],\n",
       "       [-0.05601596, -0.04826775],\n",
       "       [-0.01390829, -0.05403575],\n",
       "       [-0.07005185, -0.11171584],\n",
       "       [ 0.07030705,  0.03825238],\n",
       "       [ 0.01416349,  0.0469044 ],\n",
       "       [ 0.08434294,  0.10602649],\n",
       "       [-0.02794418,  0.01373835],\n",
       "       [-0.02794418,  0.00508633],\n",
       "       [-0.07005185, -0.03673173],\n",
       "       [ 0.08434294,  0.1161205 ],\n",
       "       [ 0.05627116, -0.0165437 ],\n",
       "       [-0.02794418,  0.00508633],\n",
       "       [ 0.0001276 , -0.01077569],\n",
       "       [ 0.04223527,  0.02671637],\n",
       "       [-0.05601596, -0.05115175],\n",
       "       [ 0.08434294,  0.08151245],\n",
       "       [ 0.02819938,  0.01229635],\n",
       "       [ 0.07030705,  0.07574444],\n",
       "       [ 0.01416349,  0.00364433],\n",
       "       [ 0.02819938,  0.01373835],\n",
       "       [ 0.0001276 ,  0.02815837],\n",
       "       [ 0.04223527,  0.06565043],\n",
       "       [ 0.01416349,  0.04402039],\n",
       "       [-0.07005185, -0.0843178 ],\n",
       "       [-0.07005185, -0.04970975],\n",
       "       [ 0.02819938, -0.01077569],\n",
       "       [ 0.0001276 ,  0.02671637],\n",
       "       [-0.01390829,  0.07430244],\n",
       "       [ 0.08434294,  0.0469044 ],\n",
       "       [ 0.12645061,  0.08007045],\n",
       "       [ 0.07030705,  0.03104237],\n",
       "       [ 0.01416349, -0.00068167],\n",
       "       [-0.07005185, -0.02952172],\n",
       "       [ 0.08434294,  0.03104237],\n",
       "       [ 0.08434294,  0.04257839],\n",
       "       [ 0.11241472,  0.06276642],\n",
       "       [ 0.0001276 ,  0.05988242],\n",
       "       [ 0.04223527,  0.00508633],\n",
       "       [-0.05601596, -0.02375371],\n",
       "       [ 0.0001276 ,  0.01950636],\n",
       "       [-0.05601596, -0.04970975],\n",
       "       [-0.04198007, -0.07999179],\n",
       "       [-0.01390829, -0.01221769],\n",
       "       [ 0.04223527,  0.0469044 ],\n",
       "       [ 0.01416349,  0.07141843],\n",
       "       [ 0.0001276 ,  0.03536838],\n",
       "       [-0.07005185,  0.11035249],\n",
       "       [ 0.1404865 ,  0.12765652],\n",
       "       [ 0.08434294,  0.01950636],\n",
       "       [-0.07005185,  0.0469044 ],\n",
       "       [ 0.0001276 , -0.0208697 ],\n",
       "       [-0.02794418,  0.06420842],\n",
       "       [ 0.01416349,  0.03104237],\n",
       "       [ 0.12645061,  0.13054052],\n",
       "       [ 0.05627116,  0.01518035],\n",
       "       [-0.11215952, -0.05403575],\n",
       "       [-0.12619542, -0.0857598 ],\n",
       "       [-0.05601596, -0.04105773],\n",
       "       [-0.04198007,  0.05555641],\n",
       "       [-0.01390829,  0.03681038],\n",
       "       [-0.02794418,  0.07141843],\n",
       "       [ 0.0001276 ,  0.1132365 ],\n",
       "       [ 0.07030705,  0.11035249],\n",
       "       [ 0.01416349, -0.0843178 ],\n",
       "       [-0.02794418, -0.05259375],\n",
       "       [-0.07005185, -0.03817373],\n",
       "       [-0.05601596,  0.0483464 ],\n",
       "       [ 0.04223527,  0.06276642],\n",
       "       [ 0.22470185,  0.12621452],\n",
       "       [ 0.11241472,  0.05988242],\n",
       "       [ 0.02819938, -0.03384772],\n",
       "       [ 0.05627116,  0.07574444],\n",
       "       [ 0.02819938,  0.02815837],\n",
       "       [ 0.05627116,  0.04257839],\n",
       "       [ 0.08434294,  0.05267241],\n",
       "       [-0.05601596, -0.02807971],\n",
       "       [ 0.01416349, -0.0151017 ],\n",
       "       [ 0.0001276 , -0.02375371],\n",
       "       [-0.04198007, -0.05403575],\n",
       "       [-0.07005185, -0.03240572],\n",
       "       [ 0.04223527,  0.00508633],\n",
       "       [-0.02794418, -0.00789168],\n",
       "       [ 0.0001276 ,  0.01373835],\n",
       "       [-0.05601596, -0.03096372],\n",
       "       [-0.04198007, -0.05403575],\n",
       "       [-0.11215952, -0.04970975],\n",
       "       [ 0.08434294,  0.08007045],\n",
       "       [ 0.02819938,  0.00076033],\n",
       "       [-0.01390829, -0.0151017 ],\n",
       "       [-0.11215952, -0.12901987],\n",
       "       [-0.08408774, -0.11604185],\n",
       "       [-0.09812363, -0.0857598 ],\n",
       "       [-0.14023131, -0.12901987],\n",
       "       [-0.07005185, -0.14199789],\n",
       "       [-0.04198007, -0.02807971],\n",
       "       [-0.02794418, -0.00933369],\n",
       "       [-0.08408774, -0.08143379],\n",
       "       [ 0.02819938, -0.0165437 ],\n",
       "       [ 0.01416349, -0.0857598 ],\n",
       "       [ 0.04223527,  0.02960037],\n",
       "       [-0.01390829,  0.01806435],\n",
       "       [-0.08408774, -0.11171584],\n",
       "       [-0.16830309, -0.05115175],\n",
       "       [-0.01390829,  0.00076033],\n",
       "       [ 0.01416349, -0.0843178 ],\n",
       "       [-0.04198007, -0.0828758 ],\n",
       "       [-0.11215952, -0.11604185],\n",
       "       [-0.05601596, -0.09729582],\n",
       "       [-0.08408774, -0.0843178 ],\n",
       "       [-0.05601596,  0.00364433],\n",
       "       [-0.04198007, -0.03961573],\n",
       "       [ 0.01416349, -0.0194277 ],\n",
       "       [-0.09812363, -0.06268777],\n",
       "       [-0.02794418,  0.00076033],\n",
       "       [ 0.02819938,  0.05988242],\n",
       "       [ 0.0001276 ,  0.07574444],\n",
       "       [-0.01390829,  0.07862845],\n",
       "       [-0.05601596, -0.00212368],\n",
       "       [ 0.01416349,  0.01518035],\n",
       "       [-0.07005185, -0.11315784],\n",
       "       [-0.08408774, -0.03096372],\n",
       "       [-0.11215952, -0.09729582],\n",
       "       [-0.14023131, -0.0151017 ],\n",
       "       [ 0.0001276 , -0.0194277 ],\n",
       "       [-0.01390829, -0.07999179],\n",
       "       [ 0.09837883, -0.02952172],\n",
       "       [-0.05601596, -0.11748385],\n",
       "       [ 0.02819938,  0.0483464 ],\n",
       "       [-0.01390829,  0.07286044],\n",
       "       [ 0.09837883,  0.04402039],\n",
       "       [-0.01390829, -0.00356568],\n",
       "       [ 0.01416349, -0.07999179],\n",
       "       [ 0.01416349,  0.03248438],\n",
       "       [ 0.0001276 , -0.06412977],\n",
       "       [ 0.07030705,  0.1132365 ],\n",
       "       [-0.04198007,  0.12909852],\n",
       "       [ 0.01416349, -0.03240572],\n",
       "       [-0.02794418, -0.0857598 ],\n",
       "       [-0.05601596, -0.05115175],\n",
       "       [-0.07005185, -0.09585382],\n",
       "       [ 0.01416349, -0.04249974],\n",
       "       [ 0.04223527, -0.05403575],\n",
       "       [-0.09812363, -0.14776589],\n",
       "       [-0.11215952,  0.00364433],\n",
       "       [-0.01390829, -0.0208697 ],\n",
       "       [-0.02794418, -0.01221769],\n",
       "       [-0.04198007, -0.05115175],\n",
       "       [ 0.0001276 , -0.0165437 ],\n",
       "       [ 0.01416349, -0.00789168],\n",
       "       [-0.01390829, -0.04538374],\n",
       "       [-0.02794418,  0.01950636],\n",
       "       [ 0.15452239,  0.13054052],\n",
       "       [ 0.08434294,  0.03825238],\n",
       "       [-0.07005185, -0.06124576],\n",
       "       [-0.01390829,  0.02815837],\n",
       "       [ 0.12645061,  0.1161205 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_st=np.column_stack(( Toef_st, CGPA_st,))\n",
    "A_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19044768],\n",
       "       [0.62001517]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS оценка коэффициентов центрированной регрессии\n",
    "w_hat_st=np.linalg.inv(A_st.T@A_st)@A_st.T@tag_st.values\n",
    "w_hat_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3, -2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.12\n",
    "v=np.array([1,2,3])\n",
    "F=np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "F@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "u=np.array([1,-1])\n",
    "v=np.array([1,1])\n",
    "F=np.array([[2,1],[1,2]])\n",
    "print(F@u)\n",
    "print(F@v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, -6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.13 \n",
    "f=np.array([[7,2],[1,8]])\n",
    "m=np.array([2,-1])\n",
    "f@m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=np.array([[-7,6],[-12,11]])\n",
    "l=np.array([1,1])\n",
    "f@l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
